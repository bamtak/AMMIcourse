{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'غ ظ ض ذ خ ث ت ش ر ق ص ف ع س ن م ل ك ي ط ح ز و ه د ج ب أ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alp = \"غ \tظ \tض \tذ \tخ \tث \tت \tش \tر \tق \tص \tف \tع \tس \tن \tم \tل \tك \tي \tط \tح \tز \tو \tه \tد \tج \tب \tأ\"\n",
    "alp_plit = alp.split()\n",
    "' '.join(alp_plit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session files: 0 Linker files: 20\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import nltk \n",
    "import wave \n",
    "from glob import glob \n",
    "swah = \"غ ظ ض ذ خ ث ت ش ر ق ص ف ع س ن م ل ك ي ط ح ز و ه د ج ب أ\"\n",
    "swah = \"A B C D E F G H I J K L M N O P R S T U V W Y Z \" \n",
    "#swah = 'a b d e f g h i j k l m n o p r s t v y z 0 1 2 3 4 5 6 7 8 9 à c q u w x ô ì ỳ ò' \n",
    "character_to_index = {j:i for i,j in enumerate(swah.split())} \n",
    "\n",
    "def remove_punct(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\") \n",
    "    new_words = tokenizer.tokenize(text) \n",
    "    t = '' \n",
    "    for i in new_words: \n",
    "        t+= i+' ' \n",
    "    return t \n",
    "\n",
    "path = '/home/zeinab/Documents/AMMI_Courses/14) Speech Recognition- Gabreil/Final Project & Data collection/txt files+Recor/Recording files'\n",
    "sessions = glob(path + \"/*/*/file*.txt\")\n",
    "linkers = glob(path + \"/*/*/*linker.txt\")\n",
    "\n",
    "print('Session files:',len(sessions), 'Linker files:',len(linkers))\n",
    "\n",
    "all_session_text = open(path+'/all_sessions.txt', 'w') #os.path.abspath(os.getcwd()) + \n",
    "\n",
    "for linker, sess in zip(linkers, sessions):\n",
    "    sess_read = open(sess, 'r')\n",
    "    link_read = open(linker, 'r')\n",
    "    for link, sentence in zip(link_read.readlines(), sess_read.readlines()):\n",
    "        wav_name = os.path.basename(link).replace('\\n','')\n",
    "        wav_path = glob(os.path.abspath(os.getcwd()) + \"/*/*/*/{0}\".format(wav_name)) \n",
    "        # print(os.path.abspath(os.getcwd()))\n",
    "        if len(wav_path)==0: \n",
    "            continue \n",
    "        wav_path = wav_path[0] \n",
    "        try: \n",
    "            w = wave.open(wav_path, 'r') \n",
    "            d = w.readframes(w.getnframes()) \n",
    "        except: \n",
    "            print('corrupted audio: {0} -- skipped: '.format(wav_name)) \n",
    "            # uncomment if you want to delete the corrupted file \n",
    "            # os.remove(wav_path) \n",
    "            continue \n",
    "        indices = '' \n",
    "        sentence = sentence.replace('##', '') \n",
    "        sentence = remove_punct(sentence) \n",
    "        for c in sentence: \n",
    "            if not c.isspace(): \n",
    "                indices+=str(character_to_index[c.upper()]) + ' ' \n",
    "        \n",
    "        all_session_text.writelines(wav_name[:-4] + ' ' + indices + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
